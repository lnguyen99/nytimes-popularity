{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "specific-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "import keras as ks\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.neighbors\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "closed-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_preprocess(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['abstract'] = df['abstract'].astype(str)\n",
    "    df['week_day'] = df['pub_date'].map(lambda x: pd.Timestamp.to_pydatetime(pd.Timestamp(x)).weekday())\n",
    "    df['pub_hour'] = df['pub_date'].map(lambda x: pd.Timestamp.to_pydatetime(pd.Timestamp(x)).hour)\n",
    "    \n",
    "    # List of the column names with features that should be ordinal encoded\n",
    "    ordinal_features = ['newsdesk', 'section', 'material']\n",
    "\n",
    "    # Ordinal encode all of these features\n",
    "    ordinal = sklearn.preprocessing.OrdinalEncoder()\n",
    "    df[ordinal_features] = ordinal.fit_transform(df[ordinal_features])\n",
    "\n",
    "    vectorizer = HashingVectorizer(n_features=2**4)\n",
    "\n",
    "#     # abstract\n",
    "#     encoded_abstract = pd.DataFrame(vectorizer.fit_transform(df['abstract']).A)\n",
    "#     df = pd.concat([df.reset_index(drop=True), encoded_abstract.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # headline\n",
    "    encoded_headline = pd.DataFrame(vectorizer.fit_transform(df['headline']).A)\n",
    "    df = pd.concat([df.reset_index(drop=True), encoded_headline.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    df = df.drop(['uniqueID', 'subsection', 'pub_date', 'headline', 'keywords', 'abstract'], axis=1)\n",
    "    print(df.columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saved-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  'newsdesk',    'section',   'material', 'word_count', 'is_popular',\n",
      "       'n_comments',   'week_day',   'pub_hour',            0,            1,\n",
      "                  2,            3,            4,            5,            6,\n",
      "                  7,            8,            9,           10,           11,\n",
      "                 12,           13,           14,           15],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = open_and_preprocess(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "transsexual-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_popular']\n",
    "# NOTE: REMOVING word_count DRASTICALLY IMPROVES ACCURACY\n",
    "X = df.drop(['is_popular', 'word_count', 'n_comments'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "computational-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['newsdesk',  'section', 'material', 'week_day', 'pub_hour',          0,\n",
       "                1,          2,          3,          4,          5,          6,\n",
       "                7,          8,          9,         10,         11,         12,\n",
       "               13,         14,         15],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "indoor-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12792, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "authorized-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7311449785072294\n"
     ]
    }
   ],
   "source": [
    "# PREDICTING WITH KNN\n",
    "\n",
    "# 80/20 train/test split\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# create classifiers\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# train classifiers\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "neither-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10233, 21)\n",
      "(2559, 21)\n",
      "10233\n",
      "2559\n",
      "[5152 5081]\n",
      "[1292 1267]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "print(np.unique(y_train, return_counts=True)[1])\n",
    "print(np.unique(y_test, return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sized-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "printable-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.5699 - val_loss: 0.6398 - val_accuracy: 0.6123\n",
      "Epoch 2/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6371 - val_loss: 0.6259 - val_accuracy: 0.6475\n",
      "Epoch 3/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6532 - val_loss: 0.6033 - val_accuracy: 0.6846\n",
      "Epoch 4/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6720 - val_loss: 0.5874 - val_accuracy: 0.6846\n",
      "Epoch 5/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6789 - val_loss: 0.5930 - val_accuracy: 0.6719\n",
      "Epoch 6/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6969 - val_loss: 0.5696 - val_accuracy: 0.7051\n",
      "Epoch 7/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7021 - val_loss: 0.5810 - val_accuracy: 0.6738\n",
      "Epoch 8/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7042 - val_loss: 0.5956 - val_accuracy: 0.6660\n",
      "Epoch 9/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7145 - val_loss: 0.5703 - val_accuracy: 0.6963\n",
      "Epoch 10/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7167 - val_loss: 0.5477 - val_accuracy: 0.7148\n",
      "Epoch 11/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7125 - val_loss: 0.5615 - val_accuracy: 0.6953\n",
      "Epoch 12/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7216 - val_loss: 0.5593 - val_accuracy: 0.7129\n",
      "Epoch 13/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7245 - val_loss: 0.5496 - val_accuracy: 0.7256\n",
      "Epoch 14/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7234 - val_loss: 0.5583 - val_accuracy: 0.7119\n",
      "Epoch 15/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7283 - val_loss: 0.5445 - val_accuracy: 0.7148\n",
      "Epoch 16/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7358 - val_loss: 0.5505 - val_accuracy: 0.7119\n",
      "Epoch 17/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7337 - val_loss: 0.5396 - val_accuracy: 0.7334\n",
      "Epoch 18/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7448 - val_loss: 0.5367 - val_accuracy: 0.7324\n",
      "Epoch 19/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7356 - val_loss: 0.5522 - val_accuracy: 0.7197\n",
      "Epoch 20/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7356 - val_loss: 0.5592 - val_accuracy: 0.6973\n",
      "Epoch 21/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7384 - val_loss: 0.5408 - val_accuracy: 0.7158\n",
      "Epoch 22/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7416 - val_loss: 0.5499 - val_accuracy: 0.7314\n",
      "Epoch 23/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7449 - val_loss: 0.5456 - val_accuracy: 0.7373\n",
      "Epoch 24/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7414 - val_loss: 0.5523 - val_accuracy: 0.7363\n",
      "Epoch 25/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7393 - val_loss: 0.5430 - val_accuracy: 0.7158\n",
      "Epoch 26/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7501 - val_loss: 0.5437 - val_accuracy: 0.7275\n",
      "Epoch 27/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7486 - val_loss: 0.5560 - val_accuracy: 0.7246\n",
      "Epoch 28/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7496 - val_loss: 0.5562 - val_accuracy: 0.7246\n",
      "Epoch 29/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7474 - val_loss: 0.5485 - val_accuracy: 0.7217\n",
      "Epoch 30/30\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7501 - val_loss: 0.5468 - val_accuracy: 0.7305\n",
      "The test accuracy is 0.722547870261821\n"
     ]
    }
   ],
   "source": [
    "model = ks.models.Sequential()\n",
    "model.add(ks.layers.Flatten(input_shape=[shape]))\n",
    "model.add(ks.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(ks.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(ks.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(ks.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(ks.layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.1)\n",
    "test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "test_accuracy = metrics.accuracy_score(y_test, test_predictions)\n",
    "print(f\"The test accuracy is {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "convinced-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  'newsdesk',    'section',   'material', 'word_count', 'is_popular',\n",
      "         'week_day',   'pub_hour',            0,            1,            2,\n",
      "                  3,            4,            5,            6,            7,\n",
      "                  8,            9,           10,           11,           12,\n",
      "                 13,           14,           15],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set:\n",
    "ts = open_and_preprocess(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dried-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ts['is_popular']\n",
    "ts = ts.drop(['is_popular', 'word_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prerequisite-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for the shallow model on the test set is 0.609261576971214\n"
     ]
    }
   ],
   "source": [
    "# SHALLOW MODEL PREDICTION\n",
    "y_test_pred = knn.predict(ts)\n",
    "accuracy = sklearn.metrics.accuracy_score(labels, y_test_pred)\n",
    "print(f\"The test accuracy for the shallow model on the test set is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "guilty-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy for the sequential model on the test set is 0.7158948685857321\n"
     ]
    }
   ],
   "source": [
    "# SEQUENTIAL MODEL PREDICTION\n",
    "test_predictions = np.argmax(model.predict(ts), axis=1)\n",
    "test_accuracy = metrics.accuracy_score(labels, test_predictions)\n",
    "print(f\"The test accuracy for the sequential model on the test set is {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
